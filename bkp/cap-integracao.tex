%% ------------------------------------------------------------------------- %%
\chapter{Integração de dados}
\label{cap:integracao}

%\citep{Vettor2014} A Service Oriented Architecture for Linked Data Integration

Vivemos em meio a um cenário em que a informação é constantemente exposta não só pelos meios tradicionais da Web, a partir de páginas dinâmicas HTML, mas também facilitada nos diversos aplicativos por meio de interfaces para a recuperação de informação em software chamadas API (\emph{Application Programming Interface}) com o propósito de permitir ao usuário final a criação de sistemas mais ricos que integram o conteúdo do aplicativo com outros de interesse do usuário. Exemplos de empresas que trabalham dessa forma são os mais diversos e compreendem grandes empresas de tecnologia como Facebook, LinkdIn, Amazon, Youtube, Dropbox, Instagram, Flickr, Twitter, entre outros. Por outro lado, Além disso, toda essa informação e uma considerável parcela do conteúdo da internet está confinado a esses silos de informação e isso dificulta uma visão homogênea e extração de dados sobre um determinado domínio de interesse \citep{Heath2008, Civili2013}. 

A necessidade em gerenciar vastas quantidades de informações provenientes de fontes de dados heterogêneas têm incentivado a pesquisa em maneiras mais inteligentes de se realizar a integração de dados sobre um mesmo domínio \citep{Wang, Vettor2014}.
A integração e busca em fontes de dados heterogêneas tem sido um tópico muito explorado uma vez que é cada vez mais complicado o acesso a informações relevantes nesse contexto dada a velocidade de exposição de novos conteúdos e a grande quantidade de diferentes tipos de formatos. São dados em grande quantidade, desorganizados e desconectados entre eles ou outras fontes de informação na Web. Desse modo, a integração de dados é prover ao usuário uma maneira de acesso uniforme a múltiplas fontes de dados heterogêneas \citep{Wang} mas ainda são poucas as soluções genéricas para converter e conectar fontes de dados de origens diversas em um conjunto de dados único e coerente. 

A combinação de dados não é um processo trivial e exige soluções que vão desde formas para lidar com as divergências entre documentos, duplicações e ruídos. É um processo que exige adaptação das fontes de informação a nível sintático, estrutural e semântico \citep{Vettor2014}. A nível sintático porque o formato dos dados pode ser diferente já que podemos, por exemplo, querer combinar a informação contida em um banco de dados com a contida em documentos XML. A nível estrutural porque mesmo que os documentos sejam do mesmo tipo, por exemplo páginas HTML, a estrutura pode não ser igual. Por fim, a nível semântico porque a representação do conhecimento nos documentos que terão a informação combinada pode ser diferente. Além disso, dada a ao recuperar e combinar informações provenientes de múltiplos recursos é possível que exista repetição de informação, ruídos, imprecisão ou outros tipos de inconsistência que podem causar perda de significado ou mal-entendidos que podem ser prejudiciais ao resultado final da integração \citep{Vettor2014}.

A fim de auxiliar a resolução possíveis problemas decorrentes da integração de dados, máquinas podem ser empregadas para desempenhar um papel relevante. Em outras palavras, há a necessidade de oferecer algoritmos e descrições semânticas precisas dos dados trabalhados para que o computador possa interpreta-las corretamente entregando melhores resultados \citep{Vettor2014}. Por esse motivo, vários linhas de estudos convergem e vão desde o uso de ontologias para mapear um domínio comum visando a solução do problema da integração de dados heterogêneos \citep{Ahmed2008}, a integração baseada em Sistemas Multi-Agentes \citep{Sui2009} ou o acesso a informação baseado em ontologias \citep{Civili2013, Lembo2014, Kharlamov2013}. 

Levando em consideração que a maior parte dos documentos existentes na Web está definida valendo-se de formatos semi-estruturados, e.g. XML, é de se esperar a integração de dados por meio de anotações semânticas \citep{May}. Por essa razão, iniciativas como o SIOC \citep{Bojars2008} buscam uma proposta valendo-se do apontamento ontológico em Resource Description Framework(RDF) \citep{RDFWorkingGroup2014} mas visando à conexão de informação proveniente de comunidades sociais tais como Flickr, Youtube, Facebook e Wikipédia por meio do mapeamento das APIs disponibilizadas por estes sites. Outra linha de estudo envolve utilizar o conteúdo já existente na Web atual e convertê-lo para a Web semântica visando à integração de informação, a reutilização de dados e a evolução da Web atual para a Web semântica. O Deep Annotation, por exemplo, é um framework para prover anotação para um vasto conjunto de dados a partir de uma ferramenta que é simples e intuitiva \citep{Handschuh2003}. Trabalhos como o de \citep{AndreasHess} buscam fazer isso por meio de um mapeamento ontológico da informação a partir de um mecanismo semi-automático de marcação, no qual os usuários escolhem "tags" dentre uma lista de sugestões. Outros trabalhos como o de \citep{May} fazem o uso da linguagem de consulta XPath\footnote{\url{https://www.w3.org/TR/xpath-31/}} para selecionar os nós de um documento XML, encontrar estruturas relevantes do documento para então mapeá-las ontologicamente.

A orquestração de serviços disponibilizados na Internet é outra abordagem de estudo amplamente explorada por pesquisadores. Trabalhos como o SBWS\footnote{\url{http://asio.bbn.com/sbws.html}} e o ASSAM \citep{Hess2003, Hess2004} buscam realizar mapeamento semântico sobre uma descrição de serviços WSDL\footnote{\url{https://www.w3.org/TR/wsdl}} que funcionam sobre o procolo SOAP\footnote{\url{https://www.w3.org/TR/soap/}}. Com isso, um usuário pode anotar de forma semântica um WebService a partir de sugestões de classes ontológicas para marcar cada elemento da descrição do serviço exposto. Outros estudos buscam mapear serviços REST\footnote{\url{https://www.w3.org/2001/sw/wiki/REST}} em RDF de maneira a permitir a busca de conteúdo através de consultas SPARQL \citep{Battle2008}. Isso porque ao publicar em RDF os dados ficam acessíveis via uma linguagem de pesquisa padrão \citep{W3C_SPARQL} e torna mais fácil a integração de diferentes fontes uma vez que os dados passam a ser entendidos por máquinas\citep{Heath2008}. Já trabalhos como o SOARI \citep{Nardin2011} buscam tornar possível a interoperabilidade entre sistemas heterogêneos e distribuídos por meio de uma ontologia comum a partir da qual podem trocar informação com um mesmo entendimento de significado. 

Por fim, a exposição de dados ocultos é outro grande problema relacionado à integração da informação na Internet. Ao passo em que é cada vez maior o número de aplicações fazendo o uso de bancos de dados relacionais, o mapeamento semântico pode ser considerado como um instrumento para a relação e extração de informação relevante a partir de diferentes fontes de dados, tornando mais claro a importância em revelar dados relacionais como RDF ou Linked-Data\cite{Hellmann2009}. Ferramentas já conhecidas como o VirtuosoRDF\footnote{\url{http://virtuoso.openlinksw.com/}}, D2RQ\footnote{\url{http://d2rq.org/}}, entre outras, estão aptas para uso com a capacidade de gerar representações RDF que derivam diretamente de acordos implícitos e explícitos dos bancos de dados(BD) relacionais\citep{Hellmann2009}, permitindo assim o acesso a informação baseado em ontologias.

\section{Acesso à dados baseados em ontologias (OBDA)}
\label{sec:odba}

O paradigma para a integração de dados provenientes de fontes distintas é o OBDA (\emph{Ontology-based data access}) que baseia o acesso à informação por meio de ontologias sobre um mesmo domínio de conhecimento de interesse \citep{Civili2013, Lembo2014, Bienvenu2013}. Essa capacidade se dá a partir de uma arquitetura de três níveis constituída pela ontologia, a fontes de dados e o mapeamento entre uma e a outra \citep{Lembo2014, Civili2013}. Dessa forma é possível extrair informações de uma fonte de dados a partir de consultas que usam ontologias \citep{Bienvenu2013}. Nesse contexto, um dos primeiros representantes desse modelo é o D2RQ que realiza o mapeamento do banco de dados em estruturas semanticamente anotadas que permitem o acesso à informação por meio dessas ontologias.

O OBDA pode ser usado para enriquecer conhecimento em uma fonte de dados incompleta a ponto de trazer um conjunto mais completo de respostas para uma consulta aproveitando as capacidades de inferências por meio do raciocínio lógico dos bancos de dados semânticos \citep{Bienvenu2013, Calvanese2016}. Suponha uma fonte de dados que descreva um paciente com um Linfoma e outro paciente com Melanoma. Uma pesquisa sobre essa base de dados apenas de posse apenas dessas informações impede que seja pesquisado de forma satisfatória todos os pacientes que possuem algum tipo de câncer. Por outro lado, podemos enriquecer esses dados a partir do uso de ontologias que classificam ambos como tipos de câncer. Agora é possível extrair um resultado com um conjunto mais completo de informações úteis para o um hospital ou médico.

Sistemas como o Ontop \citep{Calvanese2016} e o o MastroStudio \citep{Civili2013} são exemplos de implementações ODBA e que expõe bancos de dados relacionais como grafos RDF virtuais a partir de mapeamentos entre ontologias e o banco de dados. O grafo RDF pode ser então ser consultado usando SPARQL já que o sistema traduz a consulta para a linguagem SQL de maneira transparente ao usuário de maneira tal que ele não precisa ter conhecimento sobre os bancos de dados nem sobre o relacionamento entre eles.





%\section{Integração de banco de dados relacionais}
%\label{sec:integracao_banco_de_dados}

%\section{Integração de dados de XML}
%\label{sec:integracao_xml}


%\citep{Vettor2014} Apesar disso, ainda há muito espaço para pesquisas em soluções que auxiliem a integração para consulta homogênea dentro de um mesmo tipo de conteúdo de dados .

%\citep{Vettor2014} Therefore, there is a need for a smart data architecture that enables the integration of heterogeneous data sources, by providing the means to annotate data with explicit semantics, merge the annotated data sets, and handle the cleaning and conflict resolution process.

%\citep{Lembo2014}
%In the past years, studies on OBDA have mainly concentrated on query answering, and various algorithms for it have been devised, as well as tools im- plementing them [6, 20, 7, 16, 4, 27, 22].

%No entanto tornar a Web atual na Web Semântica requer abordagens automatizadas para anotar dados existentes já que a anotação manual não escala \citep{Ahmed2008}.

%De acordo com \citet{Wei2013}, a integração de dados não é um processo trivial e depende de que requer a correta manutenção do relecionamento entre itens de dados extraídos de uma ou mais páginas e tranformar e maper esses dados em uma entitade de estrutura de dados alvo pré-definida.

%\citep{Vettor2014}
%The challenges mentioned previously are addressed as follows. For the semantic annotation challenge, domain ontologies and linked data tools provide us with the concepts that allow us to extend data with semantic annota- tions. Our solution relies on a scalable architecture that includes algorithms, available as linked data services, to semantically annotate data. For the data integration challenge, our proposal relies on our Data Mediation as a Service (DMaaS) approach [7], [8], that allows to perform on-the-fly adaptation of semantically annotated data, to resolve data conflicts that appear during the data integration process. For the data cleaning challenge, the data cleaning operations are exposed as linked data services to facilitate data manipulation.

%\citep{Civili2013} Data integration solutions [4] provide some support to this problem. The tools they have produced are usually classified into materialized (aka Extract-Transform-Load, ETL) and virtual systems (aka mediators). In particular, the latter aim at providing access to autonomous data sources, through a unified virtual global schema

%\citep{Lembo2014} Both industrial and research OBDA projects (see, e.g., [13, 1]) have experienced that mapping specification is a very complex activity, which requires a profound understanding of both the ontology and the data sources. Indeed, data sources are in general autonomous and pre-existing the OBDA application, and thus the way in which they are structured typically does not reflect the ontology, which is instead an independent representation of the domain of in- terest, rather than of the underlying data sources.

%In this work, we present MASTRO STUDIO, a new system offering effective capabilities for the management of OBDA appli- cations. It is based on the MASTRO reasoner for OBDA. Hence, internally, ontologies are specified in logics of the DL-Lite family of Description Logics [2], well-known for providing a good trade- off between expressivity and reasoning computational complexity. DL-Lite logics essentially capture standard conceptual modeling formalisms, such as UML Class Diagrams and Entity-Relationship Schemas, and are at the basis of OWL 2 QL, one of the tractable profiles of OWL 2, the current W3C standard language for on- tologies2. Also, in MASTRO, data sources are seen as relational databases. Finally, the relationship between the sources and the ontology is essentially expressed by a set of GAV assertions [7], which associate ontology elements with queries specified on the underlying database. By virtue of these design choices, OBDA ser- vices, such as query answering, are realized in MASTRO through a very efficient technique that reduces them, via query rewriting, to standard